# Realtime-Face-and-Emotion-Tracking
A model to track and identify emotions present on faces, from a live video stream.

Tools used:
-OpenCV
-Python
-Jupyter

Facial data is obtained from stock images using a haarcascade frontal-face classifier, imported from the <a href="https://github.com/opencv/opencv/tree/master/data/haarcascades">OpenCV github repository</a>. 
